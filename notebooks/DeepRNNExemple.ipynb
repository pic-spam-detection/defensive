{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPEh-xaU3lVp"
      },
      "source": [
        "**1. Téléchargement et Extraction du Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "0uxoHWJJ2bR1",
        "outputId": "e94ff9d0-1355-4c96-a137-a7fa31d7a3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mandygu/lingspam-dataset\n",
            "License(s): unknown\n",
            "Downloading lingspam-dataset.zip to /content\n",
            "  0% 0.00/3.12M [00:00<?, ?B/s]\n",
            "100% 3.12M/3.12M [00:00<00:00, 97.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             subject  \\\n",
              "0            job posting - apple-iss research center   \n",
              "1                                                NaN   \n",
              "2  query : letter frequencies for text identifica...   \n",
              "3                                               risk   \n",
              "4                           request book information   \n",
              "\n",
              "                                             message  label  \n",
              "0  content - length : 3386 apple-iss research cen...      0  \n",
              "1  lang classification grimes , joseph e . and ba...      0  \n",
              "2  i am posting this inquiry for sergei atamas ( ...      0  \n",
              "3  a colleague and i are researching the differin...      0  \n",
              "4  earlier this morning i was on the phone with a...      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2d365d0-a8b9-44e2-9c10-035f6d2ba73e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>message</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>job posting - apple-iss research center</td>\n",
              "      <td>content - length : 3386 apple-iss research cen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>lang classification grimes , joseph e . and ba...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>query : letter frequencies for text identifica...</td>\n",
              "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>risk</td>\n",
              "      <td>a colleague and i are researching the differin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>request book information</td>\n",
              "      <td>earlier this morning i was on the phone with a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2d365d0-a8b9-44e2-9c10-035f6d2ba73e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2d365d0-a8b9-44e2-9c10-035f6d2ba73e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2d365d0-a8b9-44e2-9c10-035f6d2ba73e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa7a47e6-9e2b-48f1-9f36-d3805f3eda60\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa7a47e6-9e2b-48f1-9f36-d3805f3eda60')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa7a47e6-9e2b-48f1-9f36-d3805f3eda60 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "kaggle_df",
              "summary": "{\n  \"name\": \"kaggle_df\",\n  \"rows\": 2893,\n  \"fields\": [\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2613,\n        \"samples\": [\n          \"donnellan complete citation\",\n          \"snow 3 1 / 2\",\n          \"sorry for the delay - fqtfsqvb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2859,\n        \"samples\": [\n          \"* * * * * * * * * * * * * * * * * * * * * * call for papers & exhibits * * * * * * * * * * * * * * * * * * * * * * * * * * = = = = = = = = = = = = = = = = appel aux communications & expositions = = = = = = = = = = = = = = = = = = = = = international conference on natural language processing and industrial applications nlp + ia 98 > > > special accent on computer assisted language learning < < < conference internationale sur le traitement automatique des langues et ses applications industrielles tal + ai 98 > > > attention speciale portee a l ' enseignement de la langue < < < august / aout 18 - 21 , 1998 moncton , new - brunswick , canada come to canada this summer . . . iwnlg august 5 - 7 in niagara - on-the - lake coling - acl & workshops august 10-16 in montreal nlp + ia / call august 18-21 in moncton topics of interest : the nlp study group ( gretal ) at l ' universite de moncton is organizing its second international conference on nlp and industrial applications . this year a special attention is given to computer assisted language learning & teaching . papers are invited on all aspects of natural language processing , including , but not limited to , * computer assisted language learning & teaching , * natural language understanding and generation of textual , spoken and hand-written language , * natural language interfaces to databases , expert systems , or industrial applications * machine translation , computer aided translation , translation aids , * syntax , semantics , pragmatics , lexicon , morphology , * dictionaries , corpora , & other language resources * multimodality * multilinguality * nlp industrial applications * papers of every kind that can help bridge the gap between the theory and practice of nlp in general and language learning in particular . language : authors are invited to submit preliminary versions of their papers not exceeding 400 words ( exclusive of references ) either in english or in french , the two official languages of the conference . proceedings would be published in the language of the submitted texts . final versions would be around 7 - 8 pages . submission : 1 ) the first page should be an identification page containing the title , the authors ' names , affiliations , addresses , a five ( 5 ) keyword list specifying the subject area , a five ( 5 ) line summary , and the name and address of the contact person . title / titre : authors info / auteurs et infos : keywords / mots clefs : summary / resume : contact person / personne contact : 2 ) abstracts should not exceed 400 words in length excluding references ( 12 pt , times roman , 1 inch margins ( 2 , 5 cm ) all around ; if using a4 please keep text within 19cm x 25 , 5 cm ) . 3 ) the identification page and the abstract should be submitted in 4 hard copies ( 12 pt , times roman , 1 inch margins ( 2 , 5 cm ) all around ; if using a4 please keep text within 16 , 5 cm x 23 cm ) to : nlp + ia 98 / tal + ai 98 pr . chadia moghrabi geta , clips , imag 385 rue de la bibliotheque bp 53 x 38041 grenoble cedex 9 france phone : + 33 4 76 51 4369 fax : + 33 4 76 51 4405 e - mail : nlp + ia-98 @ imag . fr 4 ) the identification page should also be e-mailed in plain text . refereeing : all submissions shall be refereed by three members of the program committee . international program committee : anne de roeck ( essex , uk ) arnold smith ( nrc , canada ) chadia moghrabi ( moncton , canada ) christian boitet ( geta , grenoble , france ) chrysanne dimarco ( logos , waterloo , canada ) eric wehrli ( geneva , switzerland ) eva hajicova ( charles u . , prague ) genvieve caelen - haumont ( geod , grenoble , france ) graeme hirst ( toronto , canada ) harry bunt ( tilburg , netherlands ) henry hamburger ( george mason , usa ) howard hamilton ( regina , canada ) jean - pierre chanod ( xerox , france ) johanna moore ( pennsylvania , usa ) john hutchins ( east anglia , uk ) john tait ( sunderland , uk ) junichi tsujii ( umist & tokyo , japan ) kathleen mccoy ( delaware , usa ) margaret king ( issco , switzerland ) manfred stede ( tu - berlin , germany ) marcel cori ( paris-7 , france ) mark seligman ( geta-clips & red pepper , usa ) michael levison ( queens , canada ) nocoletta calzolari ( pisa , italy ) pierre isabelle ( rali , montreal , canada ) pierrette bouillon ( geneva , switzerland ) paul tarau ( moncton , canada ) remi chadel ( inxight , xerox , france ) roberto basili ( roma , italy ) ruddy lelouche ( laval , canada ) susan armstrong ( issco , geneva , switzerland ) thierry chanier ( franche - comte , france ) thierry van steenberghe ( louvain - la - neuve , belgium ) veronica dahl ( simon fraser , canada ) yael ravin ( ibm , usa ) yorick wilks ( sheffield , uk ) schedule : submissions are due on april 28th 1998 . notification of receipt will be mailed to the contact person soon after receipt . authors will be notified of acceptance by 15 june 1998 . camera - ready copies of final full papers must be received by the 1st of august 1998 along with registration fees . participants are also requested to indicate their intention to participate in the conference as soon as possible to the same e-mail address with the single word intention in the subject line . exhibits : anyone wishing to arrange an exhibit or present a demonstration should send a brief electronic description along with a specification of physical requirements ( table size , power , telephone connections , number of chairs , etc . ) to the same address with the single word exhibit in the subject line . other activities : accompanying persons can enjoy the lovely outdoor living in new - brunswick and visit the highest tides in the world . moncton is only 20km away from the sandy beaches of shediac , la capitale mondiale du homard . conference organization : the conference is organized by gretal , groupe d ' etude sur le traitement automatique des langues at the universite ' de moncton in cooperation with geta-clips at l ' universite ' joseph fourier in grenoble . the members of the organizing committee are : chadia moghrabi , professor of computer science , conference chair jalal almhana , director & professor of computer science julien chiasson , professor of computer science sadek eid , professor of industrial engineering , director manufacturing technology centre boubaker meddeb - hamrouni , researcher geta & winsoft paul tarau , professor of computer science\\n\",\n          \"i was curious if anyone was actually interested in verifying whether armey 's slip was actually a slip . but since someone has asked what the time delay between the utterance of \\\" barney fag \\\" and his correction : having heard a replay , i would say the delay was less than a second . imo , the utterance was definitely a slip and not a slur . other factors would support this conclusion , apart from the delay , phonology , etc . , primary among them the fact that armey is n't stupid . he 's a ph . d . in economics , and has the political savvy to get himself elected majority whip . only the politically ( or linguistically ) tendentious would be likely to assert that someone of his political skills would think it to his advantage to make such an utterance . what a shame it was to see members of this list anxious to use their professional skills ( or to abuse them ) in order to make a political point . two weeks into this discussion and only now does anyone actually inquire into the data . it makes one wonder how much linguistic research is driven by other agendas , and what the quality of that research is . . . dave wharton\\n\",\n          \"* * * final call for papers and referees * * * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 1999 acm symposium on applied computing ( sac ' 99 ) special track on coordination models , languages and applications february 28 - march 2 , 1999 the menger , san antonio , texas , u . s . a . ( http : / / www . cs . ucy . ac . cy / sac99 . html ) sac ' 99 : ~ ~ ~ ~ ~ ~ ~ ~ over the past thirteen years , the acm symposium on applied computing ( sac ) has become a primary forum for applied computer scientists and application developers from around the world to interact and present their work . sac ' 99 is sponsored by the acm special interest groups sigada , sigapp , sigbio , and sigcue . authors are invited to contribute original papers in all areas of experimental computing and application development for the technical sessions . there will be a number of special tracks on such issues as programming languages , parallel and distributed computing , mobile and scientific computing , internet and the www , etc . coordination models , languages and applications track : ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ a special track on coordination models , languages and applications will be held at sac ' 99 . the term \\\" coordination \\\" here is used in a rather broad sense covering traditional models and languages ( e . g . ones based on the shared dataspace and cham metaphors ) but also other related formalisms such as configuration and architectural description frameworks , systems modeling abstractions and languages , programming skeletons , etc . this track on coordination is held for the second time as part of acm sac 's events . the cfp for the acm sac ' 98 track attracted 33 submissions from 18 countries ; 8 of those submissions were accepted as regular papers and 4 more as short papers . major topics of interest include but are not limited to the following : * novel models , languages , programming and implementation techniques . * relationship with other computational models such as object oriented , declarative ( functional , logic , constraint ) programming or extensions of them with coordination capabilities . * applications ( especially where the industry is involved ) . * theoretical aspects ( semantics , reasoning , verification ) . * software architectures and software engineering techniques . * middleware platforms ( e . g . corba ) . * all aspects related to the modeling of information systems ( groupware , internet and the web , workflow management , cscw ) . track program chair : ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ george a . papadopoulos department of computer science university of cyprus 75 kallipoleos str . , p . o . b . 537 cy-1678 , nicosia , cyprus e - mail : george @ cs . ucy . ac . cy tel : + 357 2 338705 / 06 , fax : + 357 2 339062 guidelines for submission : ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ original papers from the above-mentioned or other related areas will be considered . this includes three categories of submissions : 1 ) original and unpublished research ; 2 ) reports of innovative computing applications in the arts , sciences , engineering , business , government , education and industry ; and 3 ) reports of successful technology transfer to new problem domains . each submitted paper will be fully refereed and undergo a blind review process by at least three referees . the accepted papers in all categories will be published in the acm sac ' 99 proceedings . there will also be a special issue of the journal of programming languages , chapman & hall ( http : / / www . chapmanhall . com / jp / default . html ) with expanded versions of selected papers from those that will be accepted for this special track as regular papers . submission guidelines must be strictly followed : * submit six ( 6 ) copies of original manuscripts to the sac ' 99 coordination models , languages and applications track program chair ( address shown above ) . alternatively , submit your paper electronically in uuencoded compressed postscript format ; this is strongly encouraged . fax submissions will not be accepted . * the author ( s ) name ( s ) and address ( es ) must not appear in the body of the paper , and self-reference should be in the third person . this is to facilitate blind review . * the body of the paper should not exceed 5 , 000 words ( approximately 15 pages , double-spaced ) . * a separate cover sheet ( in the case of electronic submission this should be sent separately from the main paper ) should show the title of the paper , the author ( s ) name ( s ) and affiliation ( s ) , and the address ( including e-mail , telephone , and fax ) to which correspondence should be sent . * all submissions must be received by august 17 , 1998 . anyone wishing to review papers for this special track should contact the track program chair at the address shown above . important dates : ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ * august 17 , 1998 : paper submission . * october 15 , 1998 : author notification . * december 1 , 1998 : camera - ready copy .\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Télécharger le dataset Lingspam depuis Kaggle\n",
        "!kaggle datasets download -d mandygu/lingspam-dataset --force\n",
        "\n",
        "# Extraire le dataset\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile('/content/lingspam-dataset.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('kaggle_spam_ds')\n",
        "import pandas as pd\n",
        "\n",
        "kaggle_df = pd.read_csv('kaggle_spam_ds/messages.csv')\n",
        "kaggle_df.head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xMi-6B13ts7"
      },
      "source": [
        "**2. Chargement et Prétraitement des Emails**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zF0w65U2gd1",
        "outputId": "e17abdff-9cc7-4f1d-b9a9-074f8700e54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Nombre total d'emails : 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Télécharger les stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Définir le dossier contenant les emails\n",
        "dataset_folder = \"lingspam_dataset\"\n",
        "\n",
        "# Initialiser les listes d'emails et labels\n",
        "emails = []\n",
        "labels = []\n",
        "\n",
        "# Fonction de nettoyage des emails\n",
        "def clean_email(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"subject:.*\", \"\", text)  # Supprimer l’en-tête \"Subject:\"\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)  # Supprimer le HTML\n",
        "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)  # Supprimer les URLs\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Supprimer la ponctuation\n",
        "    text = re.sub(r\"\\d+\", \"\", text)  # Supprimer les chiffres\n",
        "    return \" \".join(word for word in text.split() if word not in stop_words)  # Supprimer les stopwords\n",
        "\n",
        "# Charger les emails du dataset\n",
        "for root, dirs, files in os.walk(dataset_folder):\n",
        "    for file in files:\n",
        "        if file.endswith(\".txt\"):  # Vérifier que c'est bien un email\n",
        "            with open(os.path.join(root, file), \"r\", encoding=\"latin-1\") as f:\n",
        "                content = f.read()\n",
        "                label = 1 if \"spmsg\" in file else 0  # Spam si \"spmsg\" est dans le nom\n",
        "                emails.append(clean_email(content))\n",
        "                labels.append(label)\n",
        "\n",
        "# Convertir en DataFrame\n",
        "df = pd.DataFrame({\"email\": emails, \"label\": labels})\n",
        "print(f\" Nombre total d'emails : {df.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLN-jYTo3zLs"
      },
      "source": [
        "**3. Tokenisation avec BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAdmIPMT2lsG",
        "outputId": "e8d59251-6442-4bdd-bc66-702ffb719659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2314/2314 [00:35<00:00, 65.42it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Vérifier si GPU disponible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Charger le tokenizer BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "emails = kaggle_df['message']\n",
        "labels = kaggle_df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(emails, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenisation des emails\n",
        "from tqdm import tqdm\n",
        "\n",
        "tokenized_inputs = []\n",
        "for email in tqdm(X_train):\n",
        "    inputs = tokenizer(email, return_tensors='pt', truncation=True, max_length=512, padding=\"max_length\")\n",
        "    tokenized_inputs.append(inputs[\"input_ids\"].squeeze(0))\n",
        "\n",
        "labels = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "\n",
        "# Créer un DataLoader\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_data = TensorDataset(torch.stack(tokenized_inputs), labels)\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WikYthe838G2"
      },
      "source": [
        "**4. Création du Modèle Deep RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2N2LbYKJ2sUy"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class DeepRNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim, output_dim, embedding_dim=256, dropout=0.5):\n",
        "        super(DeepRNNClassifier, self).__init__()\n",
        "\n",
        "        # Embedding Layer\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "\n",
        "        # Deep RNN avec 3 couches\n",
        "        self.rnn1 = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "        self.rnn2 = nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "        self.rnn3 = nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "            nn.Sigmoid()  # Activation sigmoïde pour la classification binaire\n",
        "        )\n",
        "\n",
        "    def forward(self, input_sequence):\n",
        "        embeddings = self.embedding(input_sequence)\n",
        "\n",
        "        # Passage à travers 3 couches RNN\n",
        "        hidden_states, _ = self.rnn1(embeddings)\n",
        "        hidden_states, _ = self.rnn2(hidden_states)\n",
        "        hidden_states, _ = self.rnn3(hidden_states)\n",
        "\n",
        "        # Prendre la dernière sortie du RNN\n",
        "        output = hidden_states[:, -1, :]  # (batch_size, hidden_dim)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbqI2jzB4BhC"
      },
      "source": [
        "**5. Entraînement du Modèle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWfHmju62tz0",
        "outputId": "67a13534-5577-4769-ba2d-9ee8d18c6b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Loss: 0.4747\n",
            "Epoch 2/5\n",
            "Loss: 0.4202\n",
            "Epoch 3/5\n",
            "Loss: 0.3917\n",
            "Epoch 4/5\n",
            "Loss: 0.3574\n",
            "Epoch 5/5\n",
            "Loss: 0.3680\n"
          ]
        }
      ],
      "source": [
        "# Définition des hyperparamètres\n",
        "input_dim = tokenizer.vocab_size + 1\n",
        "hidden_dim = 256\n",
        "output_dim = 1\n",
        "dropout = 0.5\n",
        "\n",
        "# Initialiser le modèle\n",
        "model = DeepRNNClassifier(input_dim, hidden_dim, output_dim, dropout=dropout).to(device)\n",
        "\n",
        "# Définir la perte et l'optimiseur\n",
        "bce = nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.00004)\n",
        "\n",
        "# Boucle d'entraînement\n",
        "losses = []\n",
        "n_epochs = 5\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        # Forward\n",
        "        output_y = model(batch_X)\n",
        "        output_y = output_y.squeeze(1)\n",
        "\n",
        "        # Calcul de la perte\n",
        "        loss = bce(output_y, batch_y.float())\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Ajouter la perte\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    epoch_loss /= len(train_loader)\n",
        "    losses.append(epoch_loss)\n",
        "    print(f\"Loss: {epoch_loss:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}